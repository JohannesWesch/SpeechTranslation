{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TYL7jnSoyvI"
   },
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GyQ4QmuoyvJ"
   },
   "source": [
    "## 1.1 Install pip and torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXp1EwvmoyvJ",
    "outputId": "11ea97bc-02c4-47ce-a8ed-228623ead68d"
   },
   "outputs": [],
   "source": [
    "!pip install pip==24.0\n",
    "!pip show torch | grep Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xET5s0CoyvK"
   },
   "source": [
    "## 1.2 Install fairseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjHYFYXvoyvK"
   },
   "source": [
    "First install fairseq, trust me, the original installation method sucks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "nu6XrdMqoyvK",
    "outputId": "81188187-2767-4c3d-9bfb-3ea5c53a8e29"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/facebookresearch/fairseq.git\n",
    "%cd fairseq\n",
    "!pip install --editable ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9Ms408FoyvL"
   },
   "source": [
    "Then we need to add a new environment variable so that we can use the fairseq command in the terminal.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Uzz0OANoyvL",
    "outputId": "7a1dd009-ccac-4feb-a183-43ac09299060"
   },
   "outputs": [],
   "source": [
    "!echo $PYTHONPATH\n",
    "import os\n",
    "os.environ['PYTHONPATH'] += \":/content/fairseq/\"\n",
    "!echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kfjRHR8oyvL"
   },
   "source": [
    "## 1.3 Install other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "uH9i8_HBoyvM",
    "outputId": "75ce1ea0-727a-41c4-f7d1-b3eecdd3f06c"
   },
   "outputs": [],
   "source": [
    "!pip install sacremoses\n",
    "!pip install sentencepiece\n",
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKdzNHIboyvM"
   },
   "source": [
    "## 1.4 Activate GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6TedPDXGoyvM",
    "outputId": "312ea54c-dd9e-4339-8b6e-2ece1ba03e57"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device(); print('Current device: ', torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    device = 'cpu'; print('Current device: CPU.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Enm4g2LYoyvM"
   },
   "source": [
    "# 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aA5SMaUVoyvM"
   },
   "source": [
    "## 2.1 Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Dlkp_du2oyvM",
    "outputId": "0bcd63b7-1875-4162-e8c2-0423bfd3c22f"
   },
   "outputs": [],
   "source": [
    "%cd /content/fairseq/examples/translation\n",
    "\n",
    "!wget -O sample_data.zip https://bwsyncandshare.kit.edu/s/Xx3D56SJmG8PwXj/download\n",
    "# If wget command not found, download the wget.exe from this website and move it to C:\\Windows\\System32: https://eternallybored.org/misc/wget/\n",
    "\n",
    "!unzip -o sample_data.zip\n",
    "# If unzip command not found, download \"Complete package, except sources\" and copy unzip.exe to C:\\Windows: https://gnuwin32.sourceforge.net/packages/unzip.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2KtLbYvoyvM"
   },
   "source": [
    "## 2.2 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ydo3DNZm3ky_",
    "outputId": "9bed873c-4c44-4eca-d0d1-7f5f5269b452"
   },
   "outputs": [],
   "source": [
    "# List files in downloaded `sample_data`\n",
    "!ls -ltr sample_data\n",
    "\n",
    "!echo -e \"\\nFirst lines of German:\\n\"\n",
    "!head sample_data/train.wikimedia.de-en.de\n",
    "!echo -e \"\\nFirst lines of English:\\n\"\n",
    "!head sample_data/train.wikimedia.de-en.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEk4ElBgoyvM"
   },
   "source": [
    "Segment the text into subwords using BPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlAmkcoFoyvN",
    "outputId": "800a2293-0c8f-420a-8e64-717f92ee96a9"
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# After execution, you can find two bpe files in the directory.\n",
    "spm.SentencePieceTrainer.train(input=\"sample_data/train.wikimedia.de-en.de,sample_data/train.wikimedia.de-en.en\",\n",
    "                               model_prefix=\"bpe\",\n",
    "                               vocab_size=10000)\n",
    "\n",
    "print('Finished training sentencepiece model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcW0K-L9oyvN"
   },
   "source": [
    "Then we use the trained segmentation model to preprocess the sentences from train/dev/test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uYl22CaoyvN"
   },
   "outputs": [],
   "source": [
    "# Load the trained sentencepiece model\n",
    "spm_model = spm.SentencePieceProcessor(model_file=\"bpe.model\")\n",
    "\n",
    "# Important: encoding=\"utf-8\"\n",
    "for partition in [\"train\", \"dev\", \"tst\"]:\n",
    "    for lang in [\"de\", \"en\"]:\n",
    "        f_out = open(f\"sample_data/spm.{partition}.wikimedia.de-en.{lang}\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "        with open(f\"sample_data/{partition}.wikimedia.de-en.{lang}\", \"r\", encoding=\"utf-8\") as f_in:\n",
    "            for line_idx, line in enumerate(f_in.readlines()):\n",
    "                # Segmented into subwords\n",
    "                line_segmented = spm_model.encode(line.strip(), out_type=str)\n",
    "                # Join the subwords into a string\n",
    "                line_segmented = \" \".join(line_segmented)\n",
    "                f_out.write(line_segmented + \"\\n\")\n",
    "\n",
    "        f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ho-VSblKoyvN"
   },
   "source": [
    "Now, we will binarize the data for training with fairseq.  \n",
    "Feel free to check the [documentation](https://fairseq.readthedocs.io/en/latest/command_line_tools.html) of fairseq commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjdIBeNToyvN",
    "outputId": "03be3365-1172-40b6-abd9-31385c7403a8"
   },
   "outputs": [],
   "source": [
    "# Preprocess/binarize the data\n",
    "TEXT=\"/content/fairseq/examples/translation/sample_data\"\n",
    "!echo $TEXT\n",
    "# Binarize the data for training\n",
    "!fairseq-preprocess \\\n",
    "    --source-lang de --target-lang en \\\n",
    "    --trainpref $TEXT/spm.train.wikimedia.de-en \\\n",
    "    --validpref $TEXT/spm.dev.wikimedia.de-en \\\n",
    "    --testpref $TEXT/spm.tst.wikimedia.de-en \\\n",
    "    --destdir data-bin/iwslt14.de-en \\\n",
    "    --thresholdtgt 0 --thresholdsrc 0 \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mcibk4KaoyvN"
   },
   "source": [
    "The data preprocessing is completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bo0HfrH-oyvN"
   },
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68RdHhFfoyvN",
    "outputId": "31b9c474-0886-4d25-9e95-f2907acf6129"
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 fairseq-train \\\n",
    "    /content/fairseq/examples/translation/data-bin/iwslt14.de-en \\\n",
    "    --max-source-positions 4096 --max-target-positions 4096 \\\n",
    "    --skip-invalid-size-inputs-valid-test \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --keep-last-epochs 2 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --max-epoch 10 \\\n",
    "    --fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4FbCZu9oyvN"
   },
   "source": [
    "# 4. Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVERqf0KoyvN"
   },
   "source": [
    "Now we can generate translations with the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfwDbYWZoyvN",
    "outputId": "e7164d91-6303-4d8b-c663-752c9e30689a"
   },
   "outputs": [],
   "source": [
    "# TEST_INPUT=\"/content/fairseq/examples/translation/sample_data/spm.tst.de-en.de\"\n",
    "PRED_LOG=\"/content/fairseq/examples/translation/de-en.decode.log\"\n",
    "\n",
    "!fairseq-generate /content/fairseq/examples/translation/data-bin/iwslt14.de-en \\\n",
    "      --task translation \\\n",
    "      --source-lang de \\\n",
    "      --target-lang en \\\n",
    "      --path /content/fairseq/examples/translation/checkpoints/checkpoint_best.pt \\\n",
    "      --batch-size 256 \\\n",
    "      --beam 4 \\\n",
    "      --max-source-positions 4096 --max-target-positions 4096 \\\n",
    "      --skip-invalid-size-inputs-valid-test \\\n",
    "      --remove-bpe=sentencepiece > $PRED_LOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kY5ZbTnxoyvN"
   },
   "source": [
    "We extract the hypotheses and references from the decoding log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNf_RDPBoyvN",
    "outputId": "b799504b-ee72-47cc-f9aa-8d2e61d2cf9b"
   },
   "outputs": [],
   "source": [
    "!grep ^H \"de-en.decode.log\" | sed 's/^H-//g' | cut -f 3 | sed 's/ ##//g' > ./hyp.txt\n",
    "!grep ^T \"de-en.decode.log\" | sed 's/^T-//g' | cut -f 2 | sed 's/ ##//g' > ./ref.txt\n",
    "!head ./hyp.txt\n",
    "!echo \"\"\n",
    "!head ./ref.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtSSbrOBoyvN"
   },
   "source": [
    "# Section 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdfgdT24oyvO",
    "outputId": "5c6a3045-025e-4156-c920-a37db07a0efd"
   },
   "outputs": [],
   "source": [
    "!bash -c \"cat hyp.txt | sacrebleu ref.txt\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
