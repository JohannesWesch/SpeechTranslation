{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi guys, following these tips, we should be able to run this notebook on Windows soon.   \n",
    "Before we start:  \n",
    "Make sure that you open your IDE as adminstrator. Otherwise, unexpectd errors may occur when installing packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Install pip and torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pip==24.0\n",
    "!pip show torch | findstr Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Install fairseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install fairseq, trust me, the original installation method sucks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/One-sixth/fairseq.git\n",
    "# It fixes a problem that may occur if your python version>3.9.\n",
    "# In case:\n",
    "# If you meet an error here, it could be helpful to install gcc from this link:\n",
    "# https://download.visualstudio.microsoft.com/download/pr/69e24482-3b48-44d3-af65-51f866a08313/99c7677154366062a43082921f40f3ce00ef2614dbf94db23b244dd13dc9443d/vs_BuildTools.exe\n",
    "# Then download the gcc-tools (of size 5.8Gb).\n",
    "\n",
    "# Original installation method:\n",
    "# !git clone https://github.com/facebookresearch/fairseq.git\n",
    "# %cd fairseq\n",
    "# !pip install --editable ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to add a new environment variable so that we can use the fairseq command in the terminal.  \n",
    "*We will add manually！！！*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Windows, add a new environment variable using this location path.\n",
    "!pip show fairseq | findstr Location\n",
    "# ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "# Copy it and Add manually!\n",
    "\n",
    "# On Colab:\n",
    "# !echo $PYTHONPATH\n",
    "# import os\n",
    "# os.environ['PYTHONPATH'] += \":/content/fairseq/\"\n",
    "# !echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Install other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sacremoses\n",
    "!pip install sentencepiece\n",
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Activate GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device(); print('Current device: ', torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    device = 'cpu'; print('Current device: CPU.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, all packages have been installed.\n",
    "From now on, just execute the following cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we still use TED-dataset as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O sample_data.zip https://bwsyncandshare.kit.edu/s/7oo2AG8jRriLZKg/download?path=%2F\"&\"files=data.zip\"&\"downloadStartSecret=tk6qdncox5\n",
    "# If wget command not found, download the wget.exe from this website and move it to C:\\Windows\\System32: https://eternallybored.org/misc/wget/\n",
    "\n",
    "!unzip -o sample_data.zip -d dataset\n",
    "# If unzip command not found, download \"Complete package, except sources\" and copy unzip.exe to C:\\Windows: https://gnuwin32.sourceforge.net/packages/unzip.htm\n",
    "\n",
    "!del sample_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segment the text into subwords using BPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# After execution, you can find two bpe files in the directory.\n",
    "spm.SentencePieceTrainer.train(input=\"dataset/train.de-en.en,dataset/train.de-en.de\",\n",
    "                               model_prefix=\"bpe\",\n",
    "                               vocab_size=10000)\n",
    "\n",
    "print('Finished training sentencepiece model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the trained segmentation model to preprocess the sentences from train/dev/test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained sentencepiece model\n",
    "spm_model = spm.SentencePieceProcessor(model_file=\"bpe.model\")\n",
    "\n",
    "# Important: encoding=\"utf-8\"\n",
    "for partition in [\"train\", \"dev\", \"tst\"]:\n",
    "    for lang in [\"de\", \"en\"]:\n",
    "        f_out = open(f\"dataset/spm.{partition}.de-en.{lang}\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "        with open(f\"dataset/{partition}.de-en.{lang}\", \"r\", encoding=\"utf-8\") as f_in:\n",
    "            for line_idx, line in enumerate(f_in.readlines()):\n",
    "                # Segmented into subwords\n",
    "                line_segmented = spm_model.encode(line.strip(), out_type=str)\n",
    "                # Join the subwords into a string\n",
    "                line_segmented = \" \".join(line_segmented)\n",
    "                f_out.write(line_segmented + \"\\n\")\n",
    "\n",
    "        f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will binarize the data for training with fairseq.  \n",
    "Feel free to check the [documentation](https://fairseq.readthedocs.io/en/latest/command_line_tools.html) of fairseq commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess/binarize the data\n",
    "TEXT=\"dataset\"\n",
    "!echo $TEXT\n",
    "# Binarize the data for training\n",
    "!fairseq-preprocess \\\n",
    "    --source-lang en --target-lang de \\\n",
    "    --trainpref $TEXT/spm.train.de-en \\\n",
    "    --validpref $TEXT/spm.dev.de-en \\\n",
    "    --testpref $TEXT/spm.tst.de-en \\\n",
    "    --destdir binarized_data/iwslt14.de-en \\\n",
    "    --thresholdtgt 0 --thresholdsrc 0 \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data preprocessing is completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that (0.9, 0.98) in \"\", error might occurs when use ''.\n",
    "!fairseq-train \\\n",
    "    binarized_data/iwslt14.de-en \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --adam-betas \"(0.9, 0.98)\" --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --keep-last-epochs 2 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --max-epoch 20 \\\n",
    "    --fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate translations with the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ↓↓↓ Even delete this line, it works...xD\n",
    "# TEST_INPUT=\"dataset/spm.tst.de-en.de\"\n",
    "\n",
    "!fairseq-generate binarized_data/iwslt14.de-en \\\n",
    "      --task translation \\\n",
    "      --source-lang en \\\n",
    "      --target-lang de \\\n",
    "      --path checkpoints/checkpoint_best.pt \\\n",
    "      --batch-size 256 \\\n",
    "      --beam 4 \\\n",
    "      --remove-bpe=sentencepiece > \"en-de.decode.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the hypotheses and references from the decoding log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "grep ^H \"en-de.decode.log\" | sed 's/^H-//g' | cut -f 3 | sed 's/ ##//g' > ./hyp.txt\n",
    "grep ^T \"en-de.decode.log\" | sed 's/^T-//g' | cut -f 2 | sed 's/ ##//g' > ./ref.txt\n",
    "head ./hyp.txt\n",
    "head ./ref.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use BLEU as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash -c \"cat hyp.txt | sacrebleu ref.txt\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
